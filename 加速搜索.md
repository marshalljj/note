# 通过异构数据库加速搜索

## 当前问题
```sql
create table `order` (
	`id` int auto_increment primary key,
	`create_time` datetime not null default current_timestamp,
  `update_time` datetime not null default current_timestamp on update CURRENT_TIMESTAMP,
	`customer_id` int not null default 0,
	`transportation_id` int not null default 0 comment '物流编号',
	`state` varchar(20) not null default '' comment '状态',
	`amount` decimal(10, 2) not null default 0 comment '总金额'
);

create table `item` (
	`id` int auto_increment primary key,
	`create_time` datetime not null default current_timestamp,
	`goods_id` int not null default 0 '商品id',
	`price` decimal(10,2) not null default 0 comment '单价',
	`number` int not null default 0 '数量',
	`amount` decimal(10, 2) not null default 0 comment '总计',
  `order_id` int not null default 0
);
```
### 假设目标为：搜索包含某一商品（goods_id=1）且 状态为已发货(state=`transporting`)的所有订单
- sql的解决方案为：
```sql
select a.* from order a, item b where a.id=b.order_id and b.goods_id=1 and a.state='transporting' order by a.create_time limit 1,100
```
  - 会造成slow sql, 不利于应用做水平扩展
  - 不满足客户的使用需求
- 异构数据库解决方案
```json
{
    "id":1,
    "create_time":"2018-04-03 21:35:23.001",
    "update_time":"2018-04-03 21:35:23.001",
    "customer_id":1,
    "transportation_id":1,
    "state":"transporting",
    "amount":3,
    "item":[
        {
            "id":1,
            "create_time":"2018-04-03 21:35:23.001",
            "goods_id":1,
            "price":1,
            "number":1,
            "amount":1,
            "order_id":1
        },
        {
            "id":1,
            "create_time":"2018-04-03 21:35:23.001",
            "goods_id":1,
            "price":1,
            "number":1,
            "amount":1,
            "order_id":1
        }
    ]
}
```
将sql中的数据转换成如上格式，同步到elastic-search, 查询语法如下
```json
{
    "filter":[
        {
            "term":{
                "state":"transporting"
            }
        },
        {
            "term":{
                "item.goods_id":1
            }
        }
    ]
}
```
- es是专门用于查询的数据库，可以通过此方式来实现CQRS
- 不同的库关键在于数据同步(change data capture)



## 实现
### 双写
- 增加了业务复杂度
- 无法控制手工sql修复
### mq
- 消息丢失
- 无法控制手工sql修复
- 网络延时
### binlog + mq
- 消息丢失
- 网络延时

## binlog 的实现
### stream process
- 考虑消息乱序，处理的时候不应该依赖binlog的内容，而应该根据id查询数据库
### task compensate
- 扫描过期数据，进行修复。
  - 扫描范围：sql.update_time in (today)
  - 过期数据：[sql.update_time > es.update_time] or [es.update_time not exists]
